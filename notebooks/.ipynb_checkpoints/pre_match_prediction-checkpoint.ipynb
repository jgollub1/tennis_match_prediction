{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** results listed below methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-match Predictions\n",
    "\n",
    "Before play has started, an in-match prediction model cannot draw on information from the match itself. Then, before a match between players $i$ and $j$ commences, it makes sense that this model should use the most well-informed pre-match forecast $\\hat{\\pi}_{ij}(t)$ as a starting point for predictions. Therefore, we first explore pre-match models as a starting point for in-match prediction.\n",
    "\n",
    "Earlier this year, Kovalchik released a survey of eleven different pre-match prediction models, assessing them side-by-side in accuracy, log-loss, calibration, and discrimination. 538's elo-based model and the Bookmaker Consensus Model performed the best. Elo-based prediction incorporates player $i$ and $j$'s entire match histories, while the BCM model incorporates all information encoded in the betting market. However, the paper leaves out a point-based method  devised by Klaassen and Magnus that derives serving probabilities from historical player data (combining player outcomes).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elo Rating System\n",
    "\n",
    "Elo was originally developed as a head-to-head rating system for chess players (1978). Recently, 538's elo variant has gained prominence in the media. For match $t$ between $p_i$ and $p_j$ with elo ratings $E_i(t)$ and $E_j(t)$, $p_i$ is forecasted to win with probability:\n",
    "\n",
    "$\\hat{\\pi}_{ij}(t) = (1 + 10*\\frac{E_j(t)-E_i(t)}{400})^{-1}$\n",
    "\n",
    "\n",
    "$p_i$'s rating for the following match $t+1$ is then updated accordingly:\n",
    "\n",
    "$E_i(t+1) = E_i(t) + K_{it}*(\\hat{\\pi}_{ij}(t)-W_i(t))$\n",
    "\n",
    "$W_i(t)$ is an indicator for whether $p_i$ won the given match, while $K_{it}$ is the learning rate for $p_i$ at time $t$. According to 538's analysts, elo ratings perform optimally when allowing $K_{it}$ to  decay slowly over time. With $m_i(t)$ representing the $p_i$'s career matches played at time $t$ we update our learning rate:\n",
    "\n",
    "$K_{it} = 250/(5+m(t))^{.4} $\n",
    "\n",
    "This variant updates a player's elo most quickly when we have no information about a player and makes smaller changes as $m_i(t)$ accumulates. To apply this elo rating method to our dataset, we initalize each player's elo rating at $E_i(0)=1500$ and match history $m_i(0)=0$. Then, we iterate through all tour-level matches from 1968-2017 in chronological order, storing $E_i(t),E_j(t)$ for each match and updating each player's elo accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point-based Model\n",
    "\n",
    "The hierarchical Markov Model offers an analytical solution to win probability $\\hat{\\pi}_{ij}(t)$ between players $p_i$ and $p_j$, given serving probabilities $f_{ij}$,$f_{ji}$. Klaassen and Magnus outline a way to estimate each player's serving probability from historical serve and return data. \n",
    "\n",
    "$f_{ij} = f_t + (f_i-f_{av})-(g_j-g_{av})$\n",
    "\n",
    "$f_{ji} = f_t + (f_j-f_{av})-(g_i-g_{av})$\n",
    "\n",
    "Each player's serve percentage is a function of their own serving ability and their opponent's returning ability. $f_t$ denotes the average serve percentage for the match's given tournament, while $f_i,f_j$ and $g_i,g_j$ represent player $i$ and $j$'s percentage of points won on serve and return, respectively. $f_{av},g_{av}$ are the tour-level averages in serve and return percentage; since all points are won by either server or returner, $f_{av} =1-g_{av}$.\n",
    "\n",
    "As per Klaassen and Magnus' implementation, we use the previous year's tournament serving statistics to calculate $f_t$ for a given tournament and year, where $(w,y)$ represents the set of all matches played at tournament $w$ in year $y$.\n",
    "\n",
    "$f_t(w,y) = \\frac{\\sum_{k \\in (w,y-1)}{\\text{# of points won on serve in match k}}}{\\sum_{k \\in (w,y-1)}\\text{# of points played in match k}}$\n",
    "\n",
    "With our tour-level match dataset, we can keep a year-long tally of serve/return statistics for each player at any point in time (for more details, see latex file). Below, we combine player statistics over the past 12 months to produce $f_{ij},f_{ji}$ for Kevin Anderson and Fernando Verdasco's 3rd round match at the 2013 Australian Open.\n",
    "\n",
    "From 2012 Australian Open statistics, $f_t=.6153$. From tour-level data spanning 2010-2017, $f_{av} = 0.6468; g_{av} = 1-f_{av} =.3532$ Using the above serve/return statistics from 02/12-01/13, we can calculate:\n",
    "\n",
    "$f_{ij} = f_t + (f_i-f_{av})-(g_j-g_{av})$ = .6153 + (.6799-.6468) - (.3795-.3532) = .6221\n",
    "\n",
    "$f_{ji} = f_t + (f_j-f_{av})-(g_i-g_{av})$ = .6153 + (.6461-.6468) - (.3478-.3532) = .6199$\n",
    "\n",
    "With the above serving percentages, Kevin Anderson is favored to win the best-of-five match with probability $M_p(0,0,0,0,0,0) = .5139$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From experimentation, we found that 30% weight to surface-specific elo ratings and serve/return statistics was optimal in minimizing cross entropy for both elo and point-based methods. Elo ratings still far outperform point-based models (70% vs 65%), yet the point-based models do improve significantly when serve/return stats are normalized by the James-Stein estimators (cross entropy decreased from .649 to .616). Still, standard elo ratings are superior a cross-entropy of .59. the  While we have yet to test a point-based model with adjusted serve/return percentages, it still seems that elo ratings provide one of the most reliable pre-match forecasts, short of betting odds. This is consistent with findings from Kovalchik's \"Searching for the GOAT of tennis win prediction\" (2017). This also suggests that an effective in-match prediction model must incorporate player's elo ratings. While this is easy to plug into logistic regression/neural nets, we must find a suitable way to incorporate this information into our point-based hierarchical Markov Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helper_functions import validate_results\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "\n",
    "# can test this on our subset of 10,000 matches as well as all matches in the database:\n",
    "df = pd.read_csv('../my_data/elo_atp_matches_21st_century_9_12.csv')\n",
    "del df['Unnamed: 0']\n",
    "\n",
    "# currently looking at 2014 tour-level matches, excluding Davis Cup\n",
    "df = df[df['match_year']==2014].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elo baseline:  0.69198837692\n",
      "0.587237989556\n",
      "0.590338806649\n",
      "surface elo baseline:  0.686176836862\n",
      "elo 538 baseline:  0.693233706932\n",
      "0.594502008319\n",
      "0.594839978027\n",
      "surface elo 538 baseline:  0.696554586966\n"
     ]
    }
   ],
   "source": [
    "print 'elo baseline: ',  sum((df['elo_diff']>0) == df['winner'])/float(len(df))\n",
    "print log_loss(df['winner'],[(1+10**(diff/-400.))**-1 for diff in df['elo_diff']])\n",
    "print log_loss(df['winner'],[(1+10**(diff/-400.))**-1 for diff in df['sf_elo_diff']])\n",
    "print 'surface elo baseline: ', sum((df['sf_elo_diff']>0) == df['winner'])/float(len(df))\n",
    "print 'elo 538 baseline: ',  sum((df['elo_diff_538']>0) == df['winner'])/float(len(df))\n",
    "print log_loss(df['winner'],[(1+10**(diff/-400.))**-1 for diff in df['elo_diff_538']])\n",
    "print log_loss(df['winner'],[(1+10**(diff/-400.))**-1 for diff in df['sf_elo_diff_538']])\n",
    "print 'surface elo 538 baseline: ', sum((df['sf_elo_diff_538']>0) == df['winner'])/float(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_prob_wgt_0.3\n",
      "accuracy:  0.64592783016\n",
      "loss:  0.611790279211\n",
      "match_prob_kls\n",
      "accuracy:  0.648005106926\n",
      "loss:  0.649001553798\n",
      "match_prob_kls_JS\n",
      "accuracy:  0.654644973732\n",
      "loss:  0.615559869649\n",
      "match_prob_sf_kls\n",
      "accuracy:  0.633882557949\n",
      "loss:  0.707407152797\n",
      "match_prob_sf_kls_JS\n",
      "accuracy:  0.634710708155\n",
      "loss:  0.638934134264\n",
      "lm columns:  ['elo_diff_538']\n",
      "accuracy:  0.690342560882\n",
      "loss:  0.583126462954\n",
      "lm columns:  ['elo_diff', 'sf_elo_diff']\n",
      "accuracy:  0.692004037232\n",
      "loss:  0.579194437512\n",
      "lm columns:  ['elo_diff_538', 'sf_elo_diff_538']\n",
      "accuracy:  0.691583060878\n",
      "loss:  0.577684055614\n",
      "lm columns:  ['elo_diff', 'sf_elo_diff', 'match_z_kls']\n",
      "accuracy:  0.689927623123\n",
      "loss:  0.579158190473\n",
      "lm columns:  ['elo_diff_538', 'sf_elo_diff_538', 'match_z_kls']\n",
      "accuracy:  0.689922447184\n",
      "loss:  0.577161195376\n"
     ]
    }
   ],
   "source": [
    "cols = [['elo_diff_538'],['elo_diff','sf_elo_diff'],['elo_diff_538','sf_elo_diff_538'],\\\n",
    "        ['elo_diff','sf_elo_diff','match_z_kls'],\\\n",
    "        ['elo_diff_538','sf_elo_diff_538','match_z_kls']]\n",
    "probs = ['match_prob_wgt_0.3',u'match_prob_kls',u'match_prob_kls_JS', u'match_prob_sf_kls',\\\n",
    "          u'match_prob_sf_kls_JS']\n",
    "n_splits = 5\n",
    "validate_results(df,probs=probs,lm_columns=cols,n_splits=n_splits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
